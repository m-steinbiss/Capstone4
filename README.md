### Capstone4: Machine Learning
This repository contains a Google Colab notebook that walks through training various machine learning models from polynomial regression to deep neural networks by using Scikit-learn and Keras. This capstone is the final unit and represents the final learning outcomes of my DS201 course. 

##Learning Objectives
By using this notebook and the supplemntary tutorial video, you'll be able to understand:
- Why data splitting and scaling are critical before training models.
- The difference between **underfitting** and **overfitting**, and how to detect them by using performance metrics.
- How increasing **model complexity** (as is demonstrated in the polynomial degree section) can affect performance.
- How **Ridge (L2) regularization** helps mitigate overfitting in high-degree polynomial models.
- Why **deeper neural networks** generally outperform simpler ones.

##Overview of the Notebook
Part 1: Regression

1.1 Generate a synthetic dataset.
1.2 Split and scale the data.
1.3 Build linear regression models using polynomial features of increasing degree to observe underfitting versus overfitting.
1.4 Apply Ridge regularization to see its effect on an overfitting model.
Part 2: Classification

2.1 Load an image dataset for classification.
2.2 Split and scale the data.
2.3 Train a "simple" feedforward Neural Network.
2.4 Train a "deeper" feedforward Neural Network.
2.5 Show the performance of our models on two different datasets.

##Visualizations
1. 
<img width="693" alt="image" src="https://github.com/user-attachments/assets/739a6ce4-f521-45fb-b9fe-7ced141112f1" />
